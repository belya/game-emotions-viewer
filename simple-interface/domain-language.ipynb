{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language spec\n",
    "- Задает последовательность ивентов\n",
    "- Нужны:\n",
    "    - Произвольный ивент\n",
    "    - Длина между ивентами\n",
    "    - Ивент из списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up -> left -> right|left -> * -> (10 s) -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = np.random.rand(1500, 3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, timeseries.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_csv('mock-session-events.csv')\n",
    "events_df['start'] = events_df['start_sec']\n",
    "events_df['end'] = events_df['end_sec'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start_sec</th>\n",
       "      <th>end_sec</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>down</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>left</td>\n",
       "      <td>0.533300</td>\n",
       "      <td>0.633300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.937970</td>\n",
       "      <td>1.037970</td>\n",
       "      <td>down</td>\n",
       "      <td>0.937970</td>\n",
       "      <td>1.037970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.410773</td>\n",
       "      <td>1.510773</td>\n",
       "      <td>right</td>\n",
       "      <td>1.410773</td>\n",
       "      <td>1.510773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.684613</td>\n",
       "      <td>1.784613</td>\n",
       "      <td>up</td>\n",
       "      <td>1.684613</td>\n",
       "      <td>1.784613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  start_sec   end_sec   type     start       end\n",
       "0           0   0.533300  0.633300   down  0.533300  0.633300\n",
       "1           1   0.533300  0.633300   left  0.533300  0.633300\n",
       "2           2   0.937970  1.037970   down  0.937970  1.037970\n",
       "3           3   1.410773  1.510773  right  1.410773  1.510773\n",
       "4           4   1.684613  1.784613     up  1.684613  1.784613"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lark\n",
      "  Downloading lark-1.0.0-py2.py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lark\n",
      "Successfully installed lark-1.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install lark --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'start'), [Token('WORD', 'Hello'), Token('WORD', 'World')])\n"
     ]
    }
   ],
   "source": [
    "from lark import Lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "start: query_part \"->\" \"[\" query_part \"]\" \"->\" query_part | \"[\" query_part \"]\" \"->\" query_part | query_part \"->\" \"[\" query_part \"]\" | \"[\" query_part \"]\"\n",
    "\n",
    "query_part: connection | node\n",
    "\n",
    "connection: node \"->\" query_part\n",
    "\n",
    "node: wildcard | interval | rejection | EVENT\n",
    "\n",
    "rejection: \"!\" EVENT\n",
    "\n",
    "interval: \"(\" NUMBER \"s\" \")\"\n",
    "\n",
    "wildcard: \"*\"\n",
    "\n",
    "NUMBER : /\\d+/\n",
    "EVENT: /\\w+/\n",
    "\n",
    "%ignore \" \"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Lark(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = l.parse(\"up -> [left -> (10s) -> up] -> * -> !left\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tree in module lark.tree object:\n",
      "\n",
      "class Tree(builtins.object)\n",
      " |  Tree(data: str, children: 'List[Union[str, Tree]]', meta: Union[lark.tree.Meta, NoneType] = None) -> None\n",
      " |  \n",
      " |  The main tree class.\n",
      " |  \n",
      " |  Creates a new tree, and stores \"data\" and \"children\" in attributes of the same name.\n",
      " |  Trees can be hashed and compared.\n",
      " |  \n",
      " |  Parameters:\n",
      " |      data: The name of the rule or alias\n",
      " |      children: List of matched sub-rules and terminals\n",
      " |      meta: Line & Column numbers (if ``propagate_positions`` is enabled).\n",
      " |          meta attributes: line, column, start_pos, end_line, end_column, end_pos\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __hash__(self) -> int\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, data: str, children: 'List[Union[str, Tree]]', meta: Union[lark.tree.Meta, NoneType] = None) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  copy(self) -> 'Tree'\n",
      " |  \n",
      " |  expand_kids_by_data(self, *data_values)\n",
      " |      Expand (inline) children with any of the given data values. Returns True if anything changed\n",
      " |  \n",
      " |  find_data(self, data: str) -> 'Iterator[Tree]'\n",
      " |      Returns all nodes of the tree whose data equals the given data.\n",
      " |  \n",
      " |  find_pred(self, pred: 'Callable[[Tree], bool]') -> 'Iterator[Tree]'\n",
      " |      Returns all nodes of the tree that evaluate pred(node) as true.\n",
      " |  \n",
      " |  iter_subtrees(self) -> 'Iterator[Tree]'\n",
      " |      Depth-first iteration.\n",
      " |      \n",
      " |      Iterates over all the subtrees, never returning to the same node twice (Lark's parse-tree is actually a DAG).\n",
      " |  \n",
      " |  iter_subtrees_topdown(self)\n",
      " |      Breadth-first iteration.\n",
      " |      \n",
      " |      Iterates over all the subtrees, return nodes in order like pretty() does.\n",
      " |  \n",
      " |  pretty(self, indent_str: str = '  ') -> str\n",
      " |      Returns an indented string representation of the tree.\n",
      " |      \n",
      " |      Great for debugging.\n",
      " |  \n",
      " |  scan_values(self, pred: 'Callable[[Union[str, Tree]], bool]') -> Iterator[str]\n",
      " |      Return all values in the tree that evaluate pred(value) as true.\n",
      " |      \n",
      " |      This can be used to find all the tokens in the tree.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> all_tokens = tree.scan_values(lambda v: isinstance(v, Token))\n",
      " |  \n",
      " |  set(self, data: str, children: 'List[Union[str, Tree]]') -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  meta\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'children': 'List[Union[str, Tree]]', 'data': <clas...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "  query_part\n",
      "    node\tup\n",
      "  query_part\n",
      "    connection\n",
      "      node\tleft\n",
      "      query_part\n",
      "        connection\n",
      "          node\n",
      "            interval\t10\n",
      "          query_part\n",
      "            node\tup\n",
      "  query_part\n",
      "    connection\n",
      "      node\n",
      "        wildcard\n",
      "      query_part\n",
      "        node\n",
      "          rejection\tleft\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( _.pretty() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_events_dictionary(events):\n",
    "    events_dict = {}\n",
    "    \n",
    "    for event in events:\n",
    "        for letter in event:\n",
    "            if letter not in events_dict.values():\n",
    "                events_dict[event] = letter\n",
    "                break\n",
    "                \n",
    "            assert False, \"No such letter\"\n",
    "    \n",
    "    return events_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_events = events_df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict = create_events_dictionary(unique_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eventql_source_string(events_df):\n",
    "    global events_dict\n",
    "    \n",
    "    parts = events_df['type'].apply(events_dict.get).tolist()\n",
    "    \n",
    "    return \"\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dldruldruldluurdluldrdlurlrldruldrludrlrlurlurlrlurlruldruldruldruldrlrlrdrldruldruldrulrldurdlurdlrlurld'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_string = get_eventql_source_string(events_df)\n",
    "source_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_event_regex(event):\n",
    "    global events_dict\n",
    "    \n",
    "    event = event.strip()\n",
    "    if event == \"*\":\n",
    "        keys = events_dict.keys()\n",
    "        keys_str = \"\".join(keys)\n",
    "        return f\"[{keys_str}]\"\n",
    "    if \"|\" in event:\n",
    "        events = [extract_event_regex(e) for e in event.split('|')]\n",
    "        \"|\".join(events)\n",
    "        return f\"({})\"\n",
    "    else:\n",
    "        letter = events_dict[event]\n",
    "        return letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sub_regex(eventql_string):\n",
    "    global events_dict\n",
    "    \n",
    "    events = eventql_string.split('->')\n",
    "    \n",
    "    regex_parts = []\n",
    "    for event in events:\n",
    "        if not event:\n",
    "            continue\n",
    "        letter = events_dict[event]\n",
    "        regex_parts.append(letter)\n",
    "    \n",
    "    return \"\".join(regex_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_regex(eventql_string):\n",
    "    eventql_string = eventql_string.replace(' ', '')\n",
    "    head, body_tail = eventql_string.split('[')\n",
    "    body, tail = body_tail.split(']')\n",
    "    \n",
    "    head_regex = extract_sub_regex(head)\n",
    "    body_regex = extract_sub_regex(body)\n",
    "    tail_regex = extract_sub_regex(tail)\n",
    "    \n",
    "    return f\"\"\"\n",
    "        (?<={head_regex})({body_regex})(?={tail_regex})\n",
    "    \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventql_regex = extract_regex('[up -> right] -> left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?<=)(ur)(?=l)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventql_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dldruldruldluurdluldrdlurlrldruldrludrlrlurlurlrlurlruldruldruldruldrlrlrdrldruldruldrulrldurdlurdlrlurld'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_regex_indices(source_string, regex):\n",
    "    positions_df = pd.DataFrame(\n",
    "        [(m.start(0), m.end(0) - 1) for m in re.finditer(regex, source_string)],\n",
    "        columns=['start', 'end']\n",
    "    )\n",
    "    \n",
    "    print(positions_df)\n",
    "    \n",
    "    start_time = events_df.iloc[\n",
    "        positions_df['start']\n",
    "    ]['start'].tolist()\n",
    "\n",
    "    end_time = events_df.iloc[\n",
    "        positions_df['end']\n",
    "    ]['end'].tolist()\n",
    "    \n",
    "    fragments_df = pd.DataFrame(\n",
    "        np.array([start_time, end_time]).T,\n",
    "        columns=['start', 'end']\n",
    "    )\n",
    "    fragments_df['type'] = ''\n",
    "    \n",
    "    return fragments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start  end\n",
      "0     23   24\n",
      "1     41   42\n",
      "2     44   45\n",
      "3     49   50\n",
      "4    101  102\n"
     ]
    }
   ],
   "source": [
    "fragments_df = search_regex_indices(source_string, eventql_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.301649</td>\n",
       "      <td>6.709698</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.680421</td>\n",
       "      <td>11.918487</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.480304</td>\n",
       "      <td>12.805356</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.525066</td>\n",
       "      <td>13.898259</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.722666</td>\n",
       "      <td>28.176576</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start        end type\n",
       "0   6.301649   6.709698     \n",
       "1  11.680421  11.918487     \n",
       "2  12.480304  12.805356     \n",
       "3  13.525066  13.898259     \n",
       "4  27.722666  28.176576     "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подсчет статистик по набору фрагментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_simple_statistics(timeseries, fragments_df):\n",
    "    if fragments_df.shape[0] == 0:\n",
    "        return {\n",
    "            'count': 0,\n",
    "            'length': 0,\n",
    "            'scores': []\n",
    "        }\n",
    "    fragments_length = fragments_df['start'] - fragments_df['end']\n",
    "    fragments_count = fragments_df.shape[0]\n",
    "    \n",
    "    mean_fragment_length = fragments_length.mean()\n",
    "    timeseries_parts = []\n",
    "    \n",
    "    for i, fragment in fragments_df.iterrows():\n",
    "        timeseries_part = timeseries[:, int(fragment['start']):int(fragment['end'])]\n",
    "        timeseries_parts.append(timeseries_part)\n",
    "        \n",
    "    timeseries_parts_concat = np.hstack(timeseries_parts)\n",
    "    \n",
    "    channel_means = timeseries_parts_concat.mean(axis=1)\n",
    "    channel_stds = timeseries_parts_concat.std(axis=1)\n",
    "    n_points = timeseries_part.shape[-1]\n",
    "    channel_scores = stats.norm.cdf(channel_means / channel_stds * np.sqrt(n_points))\n",
    "    \n",
    "    return {\n",
    "        'count': fragments_count,\n",
    "        'length': mean_fragment_length,\n",
    "        'scores': channel_scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 0, 'length': 0, 'scores': []}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_simple_statistics(timeseries, fragments_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Параметры:\n",
    "- Показывать/не показывать ивенты\n",
    "- Текущий регех событий\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
